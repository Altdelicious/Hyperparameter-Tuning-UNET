{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "83g0fEMO9ocH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292f6f87-91ff-4f11-987f-c1a1d505ccf5"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import os\n",
        "import math\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from __future__ import division, print_function\n",
        "from scipy.ndimage import rotate\n",
        "import glob\n",
        "!pip install pydicom\n",
        "!pip install mahotas\n",
        "import mahotas\n",
        "import cv2\n",
        "import pydicom\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/56/342e1f8ce5afe63bf65c23d0b2c1cd5a05600caad1c211c39725d3a4cc56/pydicom-2.0.0-py3-none-any.whl (35.4MB)\n",
            "\u001b[K     |████████████████████████████████| 35.5MB 94kB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.0.0\n",
            "Collecting mahotas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/3b/1f3fe2f86ffdb4a2fbc6baaf4ef0e6cebdd3e127de44ddd188dc2ed0d412/mahotas-1.4.11-cp36-cp36m-manylinux2010_x86_64.whl (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mahotas) (1.18.5)\n",
            "Installing collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VldBmLvI9s76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b1c97b9-ac98-426f-baab-75c663b9df53"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyI-LAlgZ4Wg"
      },
      "source": [
        "Following 2 block cells are for data generation and needs to be run only once. After that we can directly load the data from the google drive on each runtime.\n",
        "Create a folder named saved to store the inputs and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NPMU8Ja984w"
      },
      "source": [
        "path1 = \"/content/drive/My Drive/782dataset/TrainingSet/patient\"\n",
        "flag = 0\n",
        "counter = 0\n",
        "for i in range(1,17):\n",
        "  path2 = path1 + str(i).zfill(2)\n",
        "  path3 = path2 + \"/P\" + str(i).zfill(2) + \"contours-manual\"\n",
        "  path4 = path2 + \"/P\" + str(i).zfill(2) + \"dicom\"\n",
        "  for files in sorted(os.listdir(path3)):\n",
        "    dir = files[0:8]\n",
        "    path5 = path4 + \"/\" + dir + \".dcm\"\n",
        "    path6 = path3 + \"/\" + files\n",
        "    #print(path6)\n",
        "    e = pydicom.filereader.dcmread(path5)\n",
        "    if (counter%2==0):\n",
        "      X = e.pixel_array\n",
        "      #X[X >= 255] = 255\n",
        "      #X = X/np.amax(X)\n",
        "      #print(X.shape)\n",
        "      if((len(e.pixel_array)==256) & (len(e.pixel_array[0])==216)):\n",
        "        X = rotate(X,90)\n",
        "        #print(\"ulta\")\n",
        "      X = X.reshape(1,1,216,256)\n",
        "      if (flag==0):\n",
        "        train_i = X\n",
        "      else :\n",
        "        train_i = np.concatenate((train_i,X),axis=0)\n",
        "    data = np.genfromtxt(path6, delimiter=' ')\n",
        "    ps = e.PixelSpacing\n",
        "    data = np.round(data)\n",
        "    data = data.astype(int)\n",
        "    if ((len(e.pixel_array)==216) & (len(e.pixel_array[0])==256)):\n",
        "      mask = np.array(np.zeros((256,216)))\n",
        "      mahotas.polygon.fill_polygon(data,mask,color=1)\n",
        "      mask = rotate(mask,90)\n",
        "      #print(\"seedha\")\n",
        "    else :\n",
        "      mask = np.array(np.zeros((216,256)))\n",
        "      mahotas.polygon.fill_polygon(data,mask,color=1)\n",
        "      #print(\"ulta2\")\n",
        "    mask = np.flip(mask,0)\n",
        "    mask = mask.reshape(1,1,216,256)\n",
        "    if (flag==0):\n",
        "      train_o = mask\n",
        "    else :\n",
        "      train_o = np.concatenate((train_o,mask),axis=0)\n",
        "    flag=1\n",
        "    counter+=1\n",
        "\n",
        "print(train_i.shape) \n",
        "print(train_o.shape)\n",
        "\n",
        "\n",
        "input_vector = np.zeros((243,1,216,256))\n",
        "clahe = cv2.createCLAHE(clipLimit =255.0, tileGridSize=(3,3))\n",
        "for i in range(0,243):\n",
        "    cl_img = clahe.apply(train_i[i,0,:,:])\n",
        "    cl_img = cl_img*(1.0/np.amax(cl_img))\n",
        "    input_vector[i,0,:,:] = cl_img\n",
        "\n",
        "\n",
        "y = np.zeros((243,2,216,256))\n",
        "for i in range(0,486):\n",
        "    if (i%2==0):\n",
        "        y[int(i/2),0,:,:] = train_o[i,0,:,:]\n",
        "    else:\n",
        "        y[int(i/2),1,:,:] = train_o[i,0,:,:]\n",
        "print(y.shape)\n",
        "print(input_vector.shape)\n",
        "train_o = y\n",
        "train_o[train_o <= 0] = 0\n",
        "train_o[train_o >= 1] = 1\n",
        "\n",
        "\n",
        "#np.save(os.path.join('/content/drive/My Drive/782dataset/saved','train_o'),train_o)\n",
        "#np.save(os.path.join('/content/drive/My Drive/782dataset/saved','input_vector'),input_vector)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs3-biRVXa03"
      },
      "source": [
        "\n",
        "path0 = \"/content/drive/My Drive/782dataset/Test2/Test2Set/patient\"\n",
        "path1 = \"/content/drive/My Drive/782dataset/Test2/Test2SetContours/P\"\n",
        "flag = 0\n",
        "counter = 0\n",
        "for i in range(33,49):\n",
        "  #path2 = path1 + str(i).zfill(2)\n",
        "  path3 = path1 + str(i).zfill(2) + \"contours-manual\"\n",
        "  path4 = path0 + str(i).zfill(2) + \"/P\" + str(i).zfill(2) + \"dicom\"\n",
        "  #print(path3)\n",
        "  for files in sorted(os.listdir(path3)):\n",
        "    dir = files[0:8]\n",
        "    path5 = path4 + \"/\" + dir + \".dcm\"\n",
        "    path6 = path3 + \"/\" + files\n",
        "    #print(path6)\n",
        "    e = pydicom.filereader.dcmread(path5)\n",
        "    if (counter%2==0):\n",
        "      X = e.pixel_array\n",
        "      #print(X.shape)\n",
        "      if((len(e.pixel_array)==256) & (len(e.pixel_array[0])==216)):\n",
        "        X = rotate(X,90)\n",
        "        #print(\"ulta\")\n",
        "      X = X.reshape(1,1,216,256)\n",
        "      if (flag==0):\n",
        "        test2_i = X\n",
        "      else :\n",
        "        test2_i = np.concatenate((test2_i,X),axis=0)\n",
        "    data = np.genfromtxt(path6, delimiter=' ')\n",
        "    ps = e.PixelSpacing\n",
        "    data = np.round(data)\n",
        "    data = data.astype(int)\n",
        "    if ((len(e.pixel_array)==216) & (len(e.pixel_array[0])==256)):\n",
        "      mask = np.array(np.zeros((256,216)))\n",
        "      mahotas.polygon.fill_polygon(data,mask,color=1)\n",
        "      mask = rotate(mask,90)\n",
        "      #print(\"seedha\")\n",
        "    else :\n",
        "      mask = np.array(np.zeros((216,256)))\n",
        "      mahotas.polygon.fill_polygon(data,mask,color=1)\n",
        "      #print(\"ulta2\")\n",
        "    mask = np.flip(mask,0)\n",
        "    mask = mask.reshape(1,1,216,256)\n",
        "    if (flag==0):\n",
        "      test2_o = mask\n",
        "    else :\n",
        "      test2_o = np.concatenate((test2_o,mask),axis=0)\n",
        "    flag=1\n",
        "    counter+=1\n",
        "\n",
        "\n",
        "print(test2_i.shape) \n",
        "print(test2_o.shape)\n",
        "\n",
        "\n",
        "\n",
        "y = np.zeros((252,2,216,256))\n",
        "for i in range(0,504):\n",
        "  if (i%2==0):\n",
        "    y[int(i/2),0,:,:] = test2_o[i,0,:,:]\n",
        "  else:\n",
        "    y[int(i/2),1,:,:] = test2_o[i,0,:,:]\n",
        "print(y.shape)\n",
        "test2_o = y\n",
        "test2_o[test2_o <= 0] = 0\n",
        "test2_o[test2_o >= 1] = 1\n",
        "\n",
        "\n",
        "\n",
        "input_vector2 = np.zeros((252,1,216,256)) ##image with values within 0-255\n",
        "clahe = cv2.createCLAHE(clipLimit =255.0, tileGridSize=(3,3))\n",
        "for i in range(0,252):\n",
        "    cl_img = clahe.apply(test2_i[i,0,:,:])\n",
        "    cl_img = cl_img*(1.0/np.amax(cl_img))\n",
        "    input_vector2[i,0,:,:] = cl_img\n",
        "\n",
        "test2_length = input_vector2.shape[0]\n",
        "#print(np.amax(input_vector2))\n",
        "#plt.imshow((input_vector2[24,0,:,:]),cmap = 'gray')\n",
        "#print(input_vector2.shape)\n",
        "\n",
        "\n",
        "\n",
        "#np.save(os.path.join('/content/drive/My Drive/782dataset/saved','test2_o'),test2_o)\n",
        "#np.save(os.path.join('/content/drive/My Drive/782dataset/saved','input_vector2'),input_vector2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idZkqC7BY55H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1383b4-4d10-4669-bb38-6e889335f0ff"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "p_for_dropout = 0.2\n",
        "#dont know the activation function in last layer, currently no activation function used after final 1x1 conv\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def contracting_block(self, in_channels, out_channels, kernel_size=(3,3), padding=(1,1)):\n",
        "        block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding, stride=1),\n",
        "                nn.Dropout2d(p=p_for_dropout,inplace=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "                )\n",
        "        return block\n",
        "\n",
        "    def bottle_neck(self, in_channels, out_channels, kernel_size=(3,3), padding=(1,1)):\n",
        "        block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "            nn.Dropout2d(p=p_for_dropout,inplace=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "            nn.Dropout2d(p=p_for_dropout,inplace=True),\n",
        "            nn.ReLU(inplace=True)\n",
        "            \n",
        "        )\n",
        "        return block\n",
        "    \n",
        "    def expansive_block(self, in_channels, out_channels, kernel_size=(3,3), padding=(1,1)):\n",
        "        block = nn.Sequential(\n",
        "                #nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=padding),\n",
        "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "                nn.Dropout2d(p=p_for_dropout,inplace=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "                #nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=padding, output_padding=1)\n",
        "                )\n",
        "        return  block\n",
        "    \n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(UNet, self).__init__()\n",
        "        #Encode\n",
        "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
        "        self.conv_encode2 = self.contracting_block(64, 128)\n",
        "        self.conv_encode3 = self.contracting_block(128, 256)\n",
        "        #self.conv_encode4 = self.contracting_block(64, 128)\n",
        "        self.max_pool = nn.MaxPool2d(2, stride=2)\n",
        "        \n",
        "        self.neck = self.bottle_neck(256, 512)\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2)\n",
        "        self.upconv1 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3,3), stride=1, padding=(1,1))\n",
        "        self.upconv2 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(3,3), stride=1, padding=(1,1))\n",
        "        self.upconv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3), stride=1, padding=(1,1))\n",
        "\n",
        "        # Decode\n",
        "        #self.conv_decode5 = self.expansive_block(256, 128)\n",
        "        #self.conv_decode4 = self.expansive_block(256, 64)\n",
        "        self.conv_decode3 = self.expansive_block(512, 256)\n",
        "        self.conv_decode2 = self.expansive_block(256, 128)\n",
        "        self.conv_decode1 = self.expansive_block(128, 64)\n",
        "        self.final_conv = nn.Conv2d(in_channels=64, out_channels=out_channel, kernel_size=(1,1), stride=1, padding=(0,0))\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
        "        if crop:\n",
        "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
        "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
        "        return torch.cat((upsampled, bypass), 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Encode\n",
        "        encode_block1 = self.conv_encode1(x) #(128, 108, 64)\n",
        "        encode_block2 = self.conv_encode2(self.max_pool(encode_block1)) #(64, 54, 128)\n",
        "        encode_block3 = self.conv_encode3(self.max_pool(encode_block2)) #(32, 27, 256)\n",
        "        neck = self.neck(self.max_pool(encode_block3)) #(32, 27, 512)\n",
        "        #encode_block4 = self.conv_encode4(encode_block3)\n",
        "        #encode_block5 = self.conv_encode5(encode_block4)\n",
        "        \n",
        "        # Decode\n",
        "        decode_block3 = self.upconv1(self.upsample(neck)) #(64, 54, 256)\n",
        "        #print(decode_block3.size(), encode_block3.size())\n",
        "        decode_block3 = self.conv_decode3(self.crop_and_concat(decode_block3, encode_block3, crop=False)) #(64, 54, 256)\n",
        "        decode_block2 = self.upconv2(self.upsample(decode_block3)) #(128, 108, 128)\n",
        "        decode_block2 = self.conv_decode2(self.crop_and_concat(decode_block2, encode_block2, crop=False)) #(128, 108, 128)\n",
        "        decode_block1 = self.upconv3(self.upsample(decode_block2)) #(256, 216, 64)\n",
        "        decode_block1 = self.conv_decode1(self.crop_and_concat(decode_block1, encode_block1, crop=False)) #(256, 216, 64)\n",
        "        final_output = self.final_conv(decode_block1)\n",
        "        return  self.sigmoid(final_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrelWCfU-OdY"
      },
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=1, logits=False, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        else:\n",
        "            return F_loss\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        smooth = 1    \n",
        "        iflat = inputs.contiguous().view(-1)\n",
        "        tflat = targets.contiguous().view(-1)\n",
        "        intersection = (iflat * tflat).sum()\n",
        "        A_sum = torch.sum(iflat * iflat)\n",
        "        B_sum = torch.sum(tflat * tflat)\n",
        "        return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        #inputs = F.sigmoid(inputs)  \n",
        "        smooth = 1     \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + 0.5*dice_loss\n",
        "        return Dice_BCE\n",
        "\n",
        "\n",
        "#ALPHA = 0.5\n",
        "#BETA = 0.5\n",
        "\n",
        "class TverskyLoss(nn.Module):\n",
        "    def __init__(self, alpha = 0.5, beta = 0.5, weight=None, size_average=True):\n",
        "        super(TverskyLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.weight = weight\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, inputs, targets, alpha, beta):\n",
        "        smooth = 1\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        TP = (inputs * targets).sum()    \n",
        "        FP = ((1-targets) * inputs).sum()\n",
        "        FN = (targets * (1-inputs)).sum()\n",
        "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
        "        return 1 - Tversky\n",
        "\n",
        "\n",
        "class InvertedDiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(InvertedDiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        smooth = 1    \n",
        "        iflat = inputs.contiguous().view(-1)\n",
        "        tflat = targets.contiguous().view(-1)\n",
        "        intersection = ((1-iflat) * (1-tflat)).sum()\n",
        "        A_sum = torch.sum((1-iflat) * (1-iflat))\n",
        "        B_sum = torch.sum((1-tflat) * (1-tflat))\n",
        "        return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth))\n",
        "\n",
        "\n",
        "loss_dice = DiceLoss()\n",
        "loss_dice = loss_dice.to(device)\n",
        "\n",
        "loss_focal = FocalLoss(gamma=1.5)\n",
        "loss_focal = loss_focal.to(device)\n",
        "\n",
        "loss_diceBCE = DiceBCELoss()\n",
        "loss_diceBCE = loss_diceBCE.to(device)\n",
        "\n",
        "loss_tversky = TverskyLoss()\n",
        "loss_tversky = loss_tversky.to(device)\n",
        "\n",
        "loss_inverted_dice = InvertedDiceLoss()\n",
        "loss_inverted_dice = loss_inverted_dice.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggGaV2GYPRRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7543b3e-0f95-4124-c521-814e97cb18ce"
      },
      "source": [
        "input_vector = np.load(os.path.join('/content/drive/My Drive/782dataset/saved','input_vector.npy'))\n",
        "train_o = np.load(os.path.join('/content/drive/My Drive/782dataset/saved','train_o.npy'))\n",
        "\n",
        "percentage_data = int(1*243)\n",
        "\n",
        "train_i = torch.from_numpy(input_vector[0:percentage_data,:,:,:])\n",
        "train_o = torch.from_numpy(train_o[0:percentage_data,:,:,:])\n",
        "print(train_i.shape)\n",
        "print(train_o.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = UNet(1, 2)\n",
        "model = model.to(device)\n",
        "total_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(total_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([243, 1, 216, 256])\n",
            "torch.Size([243, 2, 216, 256])\n",
            "7009026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atbqu_n4-ZvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2543e253-145e-429c-9e46-1b85b0fdf4bb"
      },
      "source": [
        "learning_rate = 1e-4\n",
        "lambda1 = 0.00000001\n",
        "model_name = 'model_BCEdice_dropout_l1-l2_dict_ep'\n",
        "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00001)\n",
        "#scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 60, 70, 80, 90], gamma=0.8)\n",
        "\n",
        "batch_size = 16\n",
        "dataset_size = train_i.size()[0]\n",
        "n_batches = int(dataset_size/batch_size)\n",
        "#trainloader = DataLoader((train_i, train_o), batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "training_losses = []\n",
        "#print(dataset_size)\n",
        "\n",
        "\n",
        "\n",
        "print(device)\n",
        "for epoch in range(0, 100):  # loop over the dataset multiple times\n",
        "\n",
        "    start_event = torch.cuda.Event(enable_timing=True)\n",
        "    end_event = torch.cuda.Event(enable_timing=True)\n",
        "    start_event.record()\n",
        "\n",
        "    running_train_loss = 0.0\n",
        "    #running_val_loss = 0.0\n",
        "    num_batches = 0\n",
        "    for i in range(n_batches):\n",
        "\n",
        "        train_i_mini, train_o_mini = train_i[i*batch_size:(i+1)*batch_size,:,:,:], train_o[i*batch_size:(i+1)*batch_size,:,:,:]\n",
        "        train_i_mini, train_o_mini = train_i_mini.to(device), train_o_mini.to(device)\n",
        "        train_i_mini = train_i_mini.float()\n",
        "        train_o_mini = train_o_mini.float()\n",
        "        num_batches += 1\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        output_masks = model(train_i_mini)\n",
        "\n",
        "        #L1 regularization\n",
        "        l1_regularization = 0\n",
        "        for param in model.parameters():\n",
        "          l1_regularization += torch.norm(param, 1)**2\n",
        "        l1_regularization = l1_regularization*lambda1\n",
        "\n",
        "    \n",
        "        train_loss = loss_diceBCE(output_masks, train_o_mini) + l1_regularization\n",
        "        #train_loss = loss_tversky(output_masks, train_o_mini,alpha = 0.7, beta = 0.3)+ l1_regularization\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss += train_loss.item()\n",
        "    end_event.record()\n",
        "    torch.cuda.synchronize()  # Wait for the events to be recorded!\n",
        "    elapsed_time_ms = start_event.elapsed_time(end_event)\n",
        "    training_losses.append(running_train_loss/num_batches)\n",
        "    #val_losses.append(running_val_loss/len(reverb_val_dataset))\n",
        "    #scheduler.step()\n",
        "\n",
        "    #if (epoch % 10 == 0):\n",
        "    #    path = '/content/drive/My Drive/Summer_2020/models/model_v11_ep' + str(epoch) + '.pth'\n",
        "    #    torch.save(model.state_dict(), path)\n",
        "\n",
        "    print(\"epoch no. =\", (epoch), \", time taken =\", \"{:.2f},\".format(elapsed_time_ms/1000), \"avg. train loss =\", \"{:.7f}\".format(running_train_loss/num_batches))\n",
        "\n",
        "print('Finished Training')\n",
        "print(\"Our model: \\n\\n\", model, '\\n')\n",
        "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())\n",
        "path = '/content/drive/My Drive/782dataset/models/'+ model_name + str(epoch) + '.tar'\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_losses': training_losses,\n",
        "            }, path)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "epoch no. = 0 , time taken = 7.07, avg. train loss = 6.6714191\n",
            "epoch no. = 1 , time taken = 7.13, avg. train loss = 4.9989624\n",
            "epoch no. = 2 , time taken = 7.22, avg. train loss = 3.8306797\n",
            "epoch no. = 3 , time taken = 7.31, avg. train loss = 3.0416397\n",
            "epoch no. = 4 , time taken = 7.39, avg. train loss = 2.5077613\n",
            "epoch no. = 5 , time taken = 7.33, avg. train loss = 2.1467217\n",
            "epoch no. = 6 , time taken = 7.24, avg. train loss = 1.8988703\n",
            "epoch no. = 7 , time taken = 7.17, avg. train loss = 1.7227920\n",
            "epoch no. = 8 , time taken = 7.13, avg. train loss = 1.6013874\n",
            "epoch no. = 9 , time taken = 7.09, avg. train loss = 1.5095228\n",
            "epoch no. = 10 , time taken = 7.09, avg. train loss = 1.4402161\n",
            "epoch no. = 11 , time taken = 7.11, avg. train loss = 1.3880316\n",
            "epoch no. = 12 , time taken = 7.13, avg. train loss = 1.3472668\n",
            "epoch no. = 13 , time taken = 7.16, avg. train loss = 1.3129225\n",
            "epoch no. = 14 , time taken = 7.19, avg. train loss = 1.2871945\n",
            "epoch no. = 15 , time taken = 7.21, avg. train loss = 1.2646942\n",
            "epoch no. = 16 , time taken = 7.20, avg. train loss = 1.2418333\n",
            "epoch no. = 17 , time taken = 7.19, avg. train loss = 1.2249209\n",
            "epoch no. = 18 , time taken = 7.15, avg. train loss = 1.2097149\n",
            "epoch no. = 19 , time taken = 7.15, avg. train loss = 1.1959878\n",
            "epoch no. = 20 , time taken = 7.14, avg. train loss = 1.1798915\n",
            "epoch no. = 21 , time taken = 7.14, avg. train loss = 1.1683288\n",
            "epoch no. = 22 , time taken = 7.14, avg. train loss = 1.1563102\n",
            "epoch no. = 23 , time taken = 7.14, avg. train loss = 1.1426244\n",
            "epoch no. = 24 , time taken = 7.15, avg. train loss = 1.1309063\n",
            "epoch no. = 25 , time taken = 7.15, avg. train loss = 1.1222915\n",
            "epoch no. = 26 , time taken = 7.16, avg. train loss = 1.1097047\n",
            "epoch no. = 27 , time taken = 7.16, avg. train loss = 1.1042620\n",
            "epoch no. = 28 , time taken = 7.17, avg. train loss = 1.0960801\n",
            "epoch no. = 29 , time taken = 7.17, avg. train loss = 1.0840246\n",
            "epoch no. = 30 , time taken = 7.18, avg. train loss = 1.0790280\n",
            "epoch no. = 31 , time taken = 7.17, avg. train loss = 1.0623205\n",
            "epoch no. = 32 , time taken = 7.17, avg. train loss = 1.0542173\n",
            "epoch no. = 33 , time taken = 7.16, avg. train loss = 1.0450526\n",
            "epoch no. = 34 , time taken = 7.14, avg. train loss = 1.0374314\n",
            "epoch no. = 35 , time taken = 7.14, avg. train loss = 1.0254699\n",
            "epoch no. = 36 , time taken = 7.14, avg. train loss = 1.0199299\n",
            "epoch no. = 37 , time taken = 7.14, avg. train loss = 1.0073594\n",
            "epoch no. = 38 , time taken = 7.14, avg. train loss = 0.9977906\n",
            "epoch no. = 39 , time taken = 7.13, avg. train loss = 0.9805864\n",
            "epoch no. = 40 , time taken = 7.14, avg. train loss = 0.9807314\n",
            "epoch no. = 41 , time taken = 7.14, avg. train loss = 0.9666706\n",
            "epoch no. = 42 , time taken = 7.14, avg. train loss = 0.9638997\n",
            "epoch no. = 43 , time taken = 7.14, avg. train loss = 0.9477670\n",
            "epoch no. = 44 , time taken = 7.13, avg. train loss = 0.9475365\n",
            "epoch no. = 45 , time taken = 7.14, avg. train loss = 0.9364763\n",
            "epoch no. = 46 , time taken = 7.12, avg. train loss = 0.9152982\n",
            "epoch no. = 47 , time taken = 7.12, avg. train loss = 0.9016390\n",
            "epoch no. = 48 , time taken = 7.12, avg. train loss = 0.9116330\n",
            "epoch no. = 49 , time taken = 7.12, avg. train loss = 0.8958396\n",
            "epoch no. = 50 , time taken = 7.11, avg. train loss = 0.8852453\n",
            "epoch no. = 51 , time taken = 7.12, avg. train loss = 0.8838197\n",
            "epoch no. = 52 , time taken = 7.12, avg. train loss = 0.8722897\n",
            "epoch no. = 53 , time taken = 7.12, avg. train loss = 0.8591151\n",
            "epoch no. = 54 , time taken = 7.12, avg. train loss = 0.8626682\n",
            "epoch no. = 55 , time taken = 7.12, avg. train loss = 0.8609587\n",
            "epoch no. = 56 , time taken = 7.12, avg. train loss = 0.8409910\n",
            "epoch no. = 57 , time taken = 7.12, avg. train loss = 0.8300477\n",
            "epoch no. = 58 , time taken = 7.13, avg. train loss = 0.8304036\n",
            "epoch no. = 59 , time taken = 7.12, avg. train loss = 0.8165237\n",
            "epoch no. = 60 , time taken = 7.13, avg. train loss = 0.8048896\n",
            "epoch no. = 61 , time taken = 7.12, avg. train loss = 0.7844151\n",
            "epoch no. = 62 , time taken = 7.12, avg. train loss = 0.7884119\n",
            "epoch no. = 63 , time taken = 7.12, avg. train loss = 0.7675885\n",
            "epoch no. = 64 , time taken = 7.13, avg. train loss = 0.7600169\n",
            "epoch no. = 65 , time taken = 7.13, avg. train loss = 0.7598665\n",
            "epoch no. = 66 , time taken = 7.13, avg. train loss = 0.7495175\n",
            "epoch no. = 67 , time taken = 7.13, avg. train loss = 0.7210536\n",
            "epoch no. = 68 , time taken = 7.12, avg. train loss = 0.7290741\n",
            "epoch no. = 69 , time taken = 7.13, avg. train loss = 0.7186251\n",
            "epoch no. = 70 , time taken = 7.13, avg. train loss = 0.7183564\n",
            "epoch no. = 71 , time taken = 7.13, avg. train loss = 0.6899002\n",
            "epoch no. = 72 , time taken = 7.13, avg. train loss = 0.6687942\n",
            "epoch no. = 73 , time taken = 7.13, avg. train loss = 0.6708189\n",
            "epoch no. = 74 , time taken = 7.13, avg. train loss = 0.6644327\n",
            "epoch no. = 75 , time taken = 7.13, avg. train loss = 0.6555767\n",
            "epoch no. = 76 , time taken = 7.13, avg. train loss = 0.6458613\n",
            "epoch no. = 77 , time taken = 7.14, avg. train loss = 0.6287441\n",
            "epoch no. = 78 , time taken = 7.13, avg. train loss = 0.6255945\n",
            "epoch no. = 79 , time taken = 7.13, avg. train loss = 0.6276259\n",
            "epoch no. = 80 , time taken = 7.12, avg. train loss = 0.6097436\n",
            "epoch no. = 81 , time taken = 7.13, avg. train loss = 0.6036392\n",
            "epoch no. = 82 , time taken = 7.14, avg. train loss = 0.5824225\n",
            "epoch no. = 83 , time taken = 7.13, avg. train loss = 0.5773496\n",
            "epoch no. = 84 , time taken = 7.13, avg. train loss = 0.5856802\n",
            "epoch no. = 85 , time taken = 7.13, avg. train loss = 0.5842154\n",
            "epoch no. = 86 , time taken = 7.12, avg. train loss = 0.5644156\n",
            "epoch no. = 87 , time taken = 7.12, avg. train loss = 0.5668583\n",
            "epoch no. = 88 , time taken = 7.11, avg. train loss = 0.5486632\n",
            "epoch no. = 89 , time taken = 7.11, avg. train loss = 0.5454186\n",
            "epoch no. = 90 , time taken = 7.11, avg. train loss = 0.5342866\n",
            "epoch no. = 91 , time taken = 7.10, avg. train loss = 0.5250587\n",
            "epoch no. = 92 , time taken = 7.11, avg. train loss = 0.5309340\n",
            "epoch no. = 93 , time taken = 7.10, avg. train loss = 0.5248719\n",
            "epoch no. = 94 , time taken = 7.10, avg. train loss = 0.5096036\n",
            "epoch no. = 95 , time taken = 7.10, avg. train loss = 0.5016321\n",
            "epoch no. = 96 , time taken = 7.10, avg. train loss = 0.4985857\n",
            "epoch no. = 97 , time taken = 7.09, avg. train loss = 0.4761599\n",
            "epoch no. = 98 , time taken = 7.10, avg. train loss = 0.4769340\n",
            "epoch no. = 99 , time taken = 7.09, avg. train loss = 0.4808424\n",
            "Finished Training\n",
            "Our model: \n",
            "\n",
            " UNet(\n",
            "  (conv_encode1): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Dropout2d(p=0.2, inplace=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv_encode2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Dropout2d(p=0.2, inplace=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv_encode3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Dropout2d(p=0.2, inplace=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (neck): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Dropout2d(p=0.2, inplace=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): Dropout2d(p=0.2, inplace=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "  (upconv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (upconv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (upconv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_decode3): Sequential(\n",
            "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Dropout2d(p=0.2, inplace=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv_decode2): Sequential(\n",
            "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Dropout2d(p=0.2, inplace=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv_decode1): Sequential(\n",
            "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Dropout2d(p=0.2, inplace=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (final_conv): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (sigmoid): Sigmoid()\n",
            ") \n",
            "\n",
            "The state dict keys: \n",
            "\n",
            " odict_keys(['conv_encode1.0.weight', 'conv_encode1.0.bias', 'conv_encode1.3.weight', 'conv_encode1.3.bias', 'conv_encode1.3.running_mean', 'conv_encode1.3.running_var', 'conv_encode1.3.num_batches_tracked', 'conv_encode2.0.weight', 'conv_encode2.0.bias', 'conv_encode2.3.weight', 'conv_encode2.3.bias', 'conv_encode2.3.running_mean', 'conv_encode2.3.running_var', 'conv_encode2.3.num_batches_tracked', 'conv_encode3.0.weight', 'conv_encode3.0.bias', 'conv_encode3.3.weight', 'conv_encode3.3.bias', 'conv_encode3.3.running_mean', 'conv_encode3.3.running_var', 'conv_encode3.3.num_batches_tracked', 'neck.0.weight', 'neck.0.bias', 'neck.3.weight', 'neck.3.bias', 'upconv1.weight', 'upconv1.bias', 'upconv2.weight', 'upconv2.bias', 'upconv3.weight', 'upconv3.bias', 'conv_decode3.0.weight', 'conv_decode3.0.bias', 'conv_decode3.3.weight', 'conv_decode3.3.bias', 'conv_decode3.3.running_mean', 'conv_decode3.3.running_var', 'conv_decode3.3.num_batches_tracked', 'conv_decode2.0.weight', 'conv_decode2.0.bias', 'conv_decode2.3.weight', 'conv_decode2.3.bias', 'conv_decode2.3.running_mean', 'conv_decode2.3.running_var', 'conv_decode2.3.num_batches_tracked', 'conv_decode1.0.weight', 'conv_decode1.0.bias', 'conv_decode1.3.weight', 'conv_decode1.3.bias', 'conv_decode1.3.running_mean', 'conv_decode1.3.running_var', 'conv_decode1.3.num_batches_tracked', 'final_conv.weight', 'final_conv.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydv4EnTH-jkL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "218e7a0d-639a-488c-b663-afb7dc41d410"
      },
      "source": [
        "x = list(range(0, epoch+1))\n",
        "plt.plot(x, training_losses, color='red', label='training')\n",
        "#plt.plot(x, val_losses, color='green', label='validation')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel(model_name)\n",
        "plt.legend()\n",
        "path = '/content/drive/My Drive/782dataset/models/'+ model_name + str(epoch) + '.png'\n",
        "plt.savefig(path)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bVAeJJd-1vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7cfc40f-32d7-4f1e-95d9-be1a3a836436"
      },
      "source": [
        "#loading the model\n",
        "model = UNet(1, 2)\n",
        "#model = model.to(device)\n",
        "path = '/content/drive/My Drive/782dataset/models/'+ model_name + str(epoch) + '.tar'\n",
        "checkpoint = torch.load(path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "\n",
        "\n",
        "#TESTING\n",
        "#dice coefficient\n",
        "\n",
        "input_vector2 = np.load(os.path.join('/content/drive/My Drive/782dataset/saved','input_vector2.npy'))\n",
        "test2_o = np.load(os.path.join('/content/drive/My Drive/782dataset/saved','test2_o.npy'))\n",
        "test2_length = input_vector2.shape[0]\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "avg_dice_endo = 0.0\n",
        "avg_dice_epi = 0.0\n",
        "\n",
        "for i in range(test2_length):\n",
        "    if (i%50 == 0):\n",
        "        print(i)\n",
        "    test_image, test_target = torch.from_numpy(input_vector2[i,:,:,:]).to(device), torch.from_numpy(test2_o[i,:,:,:]).to(device)\n",
        "    test_output = model(torch.unsqueeze(test_image.float(), dim=0))\n",
        "    test_output[test_output >= 0.5] = 1\n",
        "    test_output[test_output <= 0.5] = 0\n",
        "    test_output_endo, test_output_epi = test_output[:,0,:,:], test_output[:,1,:,:]\n",
        "    test_target_endo, test_target_epi = torch.unsqueeze(test_target[0,:,:], dim=0), torch.unsqueeze(test_target[1,:,:], dim=0)\n",
        "    dice_endo = torch.sum(test_output_endo[test_target_endo==1])*2.0 / (torch.sum(test_output_endo) + torch.sum(test_target_endo))\n",
        "    dice_epi = torch.sum(test_output_epi[test_target_epi==1])*2.0 / (torch.sum(test_output_epi) + torch.sum(test_target_epi))\n",
        "    avg_dice_endo += dice_endo.item()\n",
        "    avg_dice_epi += dice_epi.item()\n",
        "\n",
        "avg_dice_endo = avg_dice_endo/test2_length\n",
        "avg_dice_epi = avg_dice_epi/test2_length\n",
        "print(\"Dice score on test2 dataset (endocardium) =\", avg_dice_endo)\n",
        "print(\"Dice score on test2 dataset (epicardium) =\", avg_dice_epi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "Dice score on test2 dataset (endocardium) = 0.637607781154473\n",
            "Dice score on test2 dataset (epicardium) = 0.6563688696189695\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}