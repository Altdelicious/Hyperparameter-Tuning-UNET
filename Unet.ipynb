{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5ovV_lzWmj6"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import os\n",
        "import math\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxAsJ6BbWnja"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZwfquvLWnlx"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "#dont know the activation function in last layer, currently no activation function used after final 1x1 conv\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def contracting_block(self, in_channels, out_channels, kernel_size=(3,3), padding=(1,1)):\n",
        "        block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding, stride=1),\n",
        "                #nn.Dropout2d(inplace=True),\n",
        "                nn.ReLU(inplace=True)\n",
        "                #nn.BatchNorm2d(out_channels)\n",
        "                )\n",
        "        return block\n",
        "\n",
        "    def bottle_neck(self, in_channels, out_channels, kernel_size=(3,3), padding=(1,1)):\n",
        "        block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return block\n",
        "    \n",
        "    def expansive_block(self, in_channels, out_channels, kernel_size=(3,3), padding=(1,1)):\n",
        "        block = nn.Sequential(\n",
        "                #nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=padding),\n",
        "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "                nn.ReLU(inplace=True)\n",
        "                #nn.BatchNorm2d(out_channels),\n",
        "                #nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=padding, output_padding=1)\n",
        "                )\n",
        "        return  block\n",
        "    \n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(UNet, self).__init__()\n",
        "        #Encode\n",
        "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
        "        self.conv_encode2 = self.contracting_block(64, 128)\n",
        "        self.conv_encode3 = self.contracting_block(128, 256)\n",
        "        #self.conv_encode4 = self.contracting_block(64, 128)\n",
        "        self.max_pool = nn.MaxPool2d(2, stride=2)\n",
        "        \n",
        "        self.neck = self.bottle_neck(256, 512)\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2)\n",
        "        self.upconv1 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3,3), stride=1, padding=(1,1))\n",
        "        self.upconv2 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(3,3), stride=1, padding=(1,1))\n",
        "        self.upconv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3), stride=1, padding=(1,1))\n",
        "\n",
        "        # Decode\n",
        "        #self.conv_decode5 = self.expansive_block(256, 128)\n",
        "        #self.conv_decode4 = self.expansive_block(256, 64)\n",
        "        self.conv_decode3 = self.expansive_block(512, 256)\n",
        "        self.conv_decode2 = self.expansive_block(256, 128)\n",
        "        self.conv_decode1 = self.expansive_block(128, 64)\n",
        "        self.final_conv = nn.Conv2d(in_channels=64, out_channels=out_channel, kernel_size=(1,1), stride=1, padding=(0,0))\n",
        "        #self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
        "        if crop:\n",
        "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
        "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
        "        return torch.cat((upsampled, bypass), 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Encode\n",
        "        encode_block1 = self.max_pool(self.conv_encode1(x)) #(128, 108, 64)\n",
        "        encode_block2 = self.max_pool(self.conv_encode2(encode_block1)) #(64, 54, 128)\n",
        "        encode_block3 = self.max_pool(self.conv_encode3(encode_block2)) #(32, 27, 256)\n",
        "        neck = self.neck(encode_block3) #(32, 27, 512)\n",
        "        #encode_block4 = self.conv_encode4(encode_block3)\n",
        "        #encode_block5 = self.conv_encode5(encode_block4)\n",
        "        \n",
        "        # Decode\n",
        "        decode_block3 = self.upconv1(self.upsample(neck)) #(64, 54, 256)\n",
        "        decode_block3 = self.conv_decode3(self.crop_and_concat(decode_block3, encode_block3, crop=False)) #(64, 54, 256)\n",
        "        decode_block2 = self.upconv2(self.upsample(decode_block3)) #(128, 108, 128)\n",
        "        decode_block2 = self.conv_decode2(self.crop_and_concat(decode_block2, encode_block2, crop=False)) #(128, 108, 128)\n",
        "        decode_block1 = self.upconv3(self.upsample(decode_block2)) #(256, 216, 64)\n",
        "        decode_block1 = self.conv_decode1(self.crop_and_concat(decode_block1, encode_block1, crop=False)) #(256, 216, 64)\n",
        "        final_output = self.final_conv(decode_block1))\n",
        "        return  final_output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGBqNQSuWnoH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTldhPPkWnsD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiM3c3cIWnu5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QFXhfnrWnxA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFJVQK5DWnzf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubQ5DiiPWnq0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}